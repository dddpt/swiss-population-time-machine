{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import json\n",
    "import copy\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# Load an example dataset with long-form data\n",
    "#fmri = sns.load_dataset(\"fmri\")\n",
    "\n",
    "# Plot the responses for different events and regions\n",
    "#plt = sns.lineplot(x=\"timepoint\", y=\"signal\",\n",
    "#             hue=\"region\", style=\"event\",\n",
    "#             data=fmri)\n",
    "\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load geolocalized points for communes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_communes_columns = [\"place\",\"zipcode\",\"zusatzziffer\",\"commune\",\"bfsnr\",\"canton\",\"X\",\"Y\",\"language\"]\n",
    "geo_communes = pd.read_csv(\"PLZO_CSV_WGS84.csv\",sep=\";\",encoding=\"utf-8\", names=geo_communes_columns, header=0)\n",
    "# was encoding windows1252 (pandas encoding=\"cp1252\"), now encoding unknown -> ?!?\n",
    "print(geo_communes.shape)\n",
    "\n",
    "# Only keep gemeinde:\n",
    "#geo_communes = geo_communes[geo_communes.place==geo_communes.commune]\n",
    "#print(geo_communes.shape)\n",
    "\n",
    "# Drop thurgau for now\n",
    "geo_communes = geo_communes[geo_communes.canton!=\"TG\"]\n",
    "print(geo_communes.shape)\n",
    "\n",
    "geo_communes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many big cities with tons of zipcodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geo_communes[geo_communes.place==\"Zürich\"]\n",
    "geo_communes[geo_communes.place.duplicated()].place.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group cities with multiple zip codes together and average their geo coordinates in a single point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageMultipleZips(df):\n",
    "    df.Y = df.Y.mean()\n",
    "    df.X = df.X.mean()\n",
    "    zipcodes = df.zipcode.values.tolist()\n",
    "    zipcodes = [zipcodes for z in zipcodes]\n",
    "    #print(\"zipcodes\")\n",
    "    #print(zipcodes)\n",
    "    #print(\"df.zipcode\")\n",
    "    #print(df.zipcode)\n",
    "    #print(\"df\")\n",
    "    #print(df)\n",
    "    df.zipcode = zipcodes\n",
    "    return df.iloc[0]\n",
    "\n",
    "geo_communes = geo_communes.groupby('place', group_keys=False).apply(averageMultipleZips)\n",
    "\n",
    "del geo_communes.index.name\n",
    "geo_communes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cleaned communes population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_communes = [\"name\",\"canton\",\"url\",\"firstmention\",\"hab_year\",\"notes\"]\n",
    "\n",
    "with open('../2_pop_extrapolation/communes_units_converted.json', 'r') as cf:\n",
    "    communes = json.load(cf)\n",
    "    \n",
    "dfcommunes = pd.DataFrame(communes)[columns_communes]\n",
    "print(dfcommunes.shape)\n",
    "\n",
    "\n",
    "# Drop thurgau for now\n",
    "dfcommunes = dfcommunes[dfcommunes.canton!=\"TG\"]\n",
    "print(dfcommunes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(communes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand correction for communes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct canton value for Basel-Stadt and Moutier\n",
    "dfcommunes.loc[dfcommunes.name==\"Moutier\",\"canton\"]=\"BE\"\n",
    "dfcommunes.loc[dfcommunes.name==\"Basel-Stadt\",\"canton\"]=\"BS\"\n",
    "# Rename communes to their nom d'usage in french:\n",
    "dfcommunes.loc[dfcommunes.name==\"Sitten\",\"name\"]=\"Sion\"\n",
    "dfcommunes.loc[dfcommunes.name==\"Neuenburg\",\"name\"]=\"Neuchâtel\"\n",
    "dfcommunes.loc[dfcommunes.name==\"Greyerz\",\"name\"]=\"Gruyères\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')\n",
    "dfcommunes.to_csv(\"communes.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape DataFrame to 1 line per datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_communes_datapoints = [\"year\",\"pop\",\"unit\",\"name\",\"canton\",\"url\",\"firstmention\",\"hab_year\",\"notes\"]\n",
    "communes_datapoints = []\n",
    "\n",
    "for commune in communes:\n",
    "    for hy in commune[\"hab_year\"]:\n",
    "        hy_dict = copy.deepcopy(commune)\n",
    "        hy_dict[\"year\"] =  hy[\"year\"]\n",
    "        hy_dict[\"pop\"] =  hy[\"pop\"]\n",
    "        hy_dict[\"unit\"] = hy[\"unit\"] if \"unit\" in hy else \"undefined\"\n",
    "        communes_datapoints.append(hy_dict)\n",
    "\n",
    "dfcommunes_datapoints = pd.DataFrame(communes_datapoints)[columns_communes_datapoints]\n",
    "dfcommunes_datapoints = dfcommunes_datapoints.drop(columns=[\"hab_year\"])\n",
    "print(dfcommunes_datapoints.shape)\n",
    "\n",
    "# Drop thurgau for now\n",
    "dfcommunes_datapoints = dfcommunes_datapoints[dfcommunes_datapoints.canton!=\"TG\"]\n",
    "print(dfcommunes_datapoints.shape)\n",
    "\n",
    "dfcommunes_datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcommunes_datapoints.to_csv(\"communes_datapoints.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge communes and geo_communes using Hungarian algorithm\n",
    "https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.optimize.linear_sum_assignment.html\n",
    "\n",
    "##### Create the fuzzy merke_keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jellyfish import jaro_distance\n",
    "\n",
    "#create unique list of names\n",
    "cantons = [ c for c in dfcommunes.canton.unique() if c!=\"MA\"]\n",
    "test_canton = \"BE\"\n",
    "\n",
    "communes_per_canton = {}\n",
    "geo_communes_per_canton = {}\n",
    "distance_matrix_per_canton = {}\n",
    "merge_keys_per_canton = {}\n",
    "for canton in cantons:\n",
    "    communes_per_canton[canton] = dfcommunes.name[dfcommunes.canton == canton].unique()\n",
    "    geo_communes_per_canton[canton] = geo_communes.place[geo_communes.canton == canton].unique()\n",
    "    \n",
    "    # do the fuzzy merge_keys\n",
    "    #if canton==test_canton:\n",
    "    def distance(i, j):\n",
    "        return 1-jaro_distance(communes_per_canton[canton][np.int(i)], geo_communes_per_canton[canton][np.int(j)])\n",
    "\n",
    "    jaroDistanceProxy = np.vectorize(distance)\n",
    "    distance_matrix_per_canton[canton] = np.fromfunction(\n",
    "        jaroDistanceProxy,\n",
    "        shape=(len(communes_per_canton[canton]),\n",
    "               len(geo_communes_per_canton[canton])))\n",
    "\n",
    "    fuzzy_merge = opt.linear_sum_assignment(distance_matrix_per_canton[canton])\n",
    "    merge_keys_per_canton[canton] = {\n",
    "        communes_per_canton[canton][fuzzy_merge[0][i]]:\n",
    "        geo_communes_per_canton[canton][fuzzy_merge[1][i]]\n",
    "        for i in range(0,len(fuzzy_merge[0]))\n",
    "    }\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print(communes_per_canton[test_canton])\n",
    "print(geo_communes_per_canton[test_canton])\n",
    "merge_keys_per_canton[test_canton]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand-correction for wrong keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_keys_per_canton[\"BE\"]['Biel (BE,'] = 'Biel/Bienne'\n",
    "merge_keys_per_canton[\"BE\"]['Biel (BE,']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the fuzzy merge:\n",
    "...on dfcommunes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcommunes[\"place\"] = \"\"\n",
    "\n",
    "for index, row in dfcommunes.iterrows():\n",
    "    if row[\"canton\"]!=\"MA\" and row[\"name\"] in merge_keys_per_canton[row[\"canton\"]]:\n",
    "        dfcommunes.loc[index,\"place\"] = merge_keys_per_canton[row[\"canton\"]][row[\"name\"]] \n",
    "    #print(dfcommunes.iloc[index])\n",
    "\n",
    "#dfcommunes.canton==\"MA\"\n",
    "result_communes = pd.merge(dfcommunes, geo_communes, on='place', how='left')\n",
    "result_communes.to_csv(\"communes_geo.csv\", sep=\";\")\n",
    "\n",
    "result_communes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...on dfcommunes_datapoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcommunes_datapoints[\"place\"] = \"\"\n",
    "\n",
    "for index, row in dfcommunes_datapoints.iterrows():\n",
    "    if row[\"canton\"]!=\"MA\" and row[\"name\"] in merge_keys_per_canton[row[\"canton\"]]:\n",
    "        dfcommunes_datapoints.loc[index,\"place\"] = merge_keys_per_canton[row[\"canton\"]][row[\"name\"]] \n",
    "    #print(dfcommunes.iloc[index])\n",
    "\n",
    "#dfcommunes.canton==\"MA\"\n",
    "result_communes_datapoints = pd.merge(dfcommunes_datapoints, geo_communes, on='place', how='left')\n",
    "result_communes_datapoints.to_csv(\"communes_datapoints_geo.csv\", sep=\";\")\n",
    "\n",
    "result_communes_datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_communes.shape)\n",
    "print(dfcommunes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nb of communes that didn't get a geo localisation:\")\n",
    "print(np.sum(dfcommunes.place==\"\"))\n",
    "dfcommunes[dfcommunes.place==\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
